# Assignments

## Problem set #1

1. Complete Exercises 4.1 in Hsieh's book.
2. Complete Exercises 4.5 in Hsieh's book. (Source data: `SWE_Nino_Nina.csv`)
3. Complete Exercises 4.6 in Hsieh's book. (Source data: `nino12_long_anom.csv` & `nino34_long_anom.csv`)
4. For the SWE data in `SWE_Nino_Nina.csv`, calculate the 95% CI of their median value using bootstrapping. Be sure to avoid the percentile method.
5. Reproduce the figure for Q3 in the Pre-course Quiz. ([Figure Link](https://drive.google.com/file/d/15WejYTcSHDGM3VNoX32WaD5r8l-BNNF-/view?usp=sharing)) *Figure credit: Nicolas P. Rougier (2021)*.

## Problem set #2

TBD.

## Problem set #3

TBD.

## Problem set #4

TBD.

## Problem set #5

TBD.

<!-- Complete Exercises 4.2, 4.3, 4.5, and 4.6 in Hsieh's book.

## Problem set #2

Complete Exercises 5.2, 5.6, 5.7, and 5.9 in Hsieh's book.

## Problem set #3

Complete Exercises 6.5, 6.6, and 8.1 in Hsieh's book.

## Problem set #4

1. Complete Exercise 12.1 in Hsieh's book.
2. Following the first question, use the support vector machine to classify the forest types in the given dataset. Feel free to choose one-versus-the-rest or one-versus-one approach (and specify your choice). Train using the first two predictors and compare the results with the linear discriminant analysis.
3. Generate a synthetic signal with added noise $y = \sin x + 0.5 \times \mathcal{N}(0, 1)$ and collect 40 data points that are distributed within the range $x = [0, 4\pi]$. Now use (a) ridge regression, (b) kernel ridge regression, and (c) Gaussian progress regression to model the data and give the prediction at the range $x = [0, 8\pi]$ with visualization. Describe and justify your kernel selection and hyperparameter tuning process whenever necessary. Compare the results from three regression methods.

## Problem set #5

Complete the following exercises in Hsieh's book with the specified requirements:

1. Exercise 14.2, including (c)
2. Exercise 12.5, but develop two prediction models instead of one. One of the models must be a random forest or a boosting model.
3. Exercise 14.4, including (b) -->